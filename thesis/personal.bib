@article{Ahrens2022,
  author        = {Kyra Ahrens and Matthias Kerzel and Jae Hee Lee and Cornelius Weber and Stefan Wermter},
  journal       = {IJCAI 2022 Workshop on Spatio-Temporal Reasoning and Learning},
  title         = {Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for Grounding Relative Directions via Multi-Task Learning},
  year          = {2022},
  month         = jul,
  abstract      = {Spatial reasoning poses a particular challenge for intelligent agents and is at the same time a prerequisite for their successful interaction and communication in the physical world. One such reasoning task is to describe the position of a target object with respect to the intrinsic orientation of some reference object via relative directions. In this paper, we introduce GRiD-A-3D, a novel diagnostic visual question-answering (VQA) dataset based on abstract objects. Our dataset allows for a fine-grained analysis of end-to-end VQA models' capabilities to ground relative directions. At the same time, model training requires considerably fewer computational resources compared with existing datasets, yet yields a comparable or even higher performance. Along with the new dataset, we provide a thorough evaluation based on two widely known end-to-end VQA architectures trained on GRiD-A-3D. We demonstrate that within a few epochs, the subtasks required to reason over relative directions, such as recognizing and locating objects in a scene and estimating their intrinsic orientations, are learned in the order in which relative directions are intuitively processed.},
  archiveprefix = {arXiv},
  eprint        = {2207.02624},
  file          = {:papers/Ahrens2022 - Knowing Earlier What Right Means to You_ a Comprehensive VQA Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups        = {Project, AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CV, cs.CL},
  primaryclass  = {cs.CV}
}

ï»¿
@article{Appelgren2020,
  author   = {Appelgren, Mattias and Lascarides, Alex},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  title    = {Interactive task learning via embodied corrective feedback},
  year     = {2020},
  issn     = {1573-7454},
  month    = {Sep},
  number   = {2},
  pages    = {54},
  volume   = {34},
  abstract = {This paper addresses a task in Interactive Task Learning (Laird et al. IEEE Intell Syst 32:6--21, 2017). The agent must learn to build towers which are constrained by rules, and whenever the agent performs an action which violates a rule the teacher provides verbal corrective feedback: e.g. ``No, red blocks should be on blue blocks''. The agent must learn to build rule compliant towers from these corrections and the context in which they were given. The agent is not only ignorant of the rules at the start of the learning process, but it also has a deficient domain model, which lacks the concepts in which the rules are expressed. Therefore an agent that takes advantage of the linguistic evidence must learn the denotations of neologisms and adapt its conceptualisation of the planning domain to incorporate those denotations. We show that by incorporating constraints on interpretation that are imposed by discourse coherence into the models for learning (Hobbs in On the coherence and structure of discourse, Stanford University, Stanford, 1985; Asher et al. in Logics of conversation, Cambridge University Press, Cambridge, 2003), an agent which utilizes linguistic evidence outperforms a strong baseline which does not.},
  day      = {27},
  doi      = {10.1007/s10458-020-09481-8},
  file     = {:papers/Appelgren2020 - Interactive Task Learning Via Embodied Corrective Feedback.pdf:PDF},
  url      = {https://doi.org/10.1007/s10458-020-09481-8}
}

@mastersthesis{Aruqi2021,
  author = {Aruqi, Ali},
  school = {University of Gothenburg},
  title  = {EMBODIED QUESTION ANSWERING IN ROBOTIC ENVIRONMENT Automatic generation of a synthetic question-answer data-set},
  year   = {2021},
  month  = nov,
  type   = {mathesis},
  file   = {:papers/Aruqi2021 - EMBODIED QUESTION ANSWERING iN ROBOTIC ENVIRONMENT Automatic Generation of a Synthetic Question Answer Data Set.pdf:PDF},
  groups = {MLT Thesis}
}

@article{Baroni2020,
  author        = {Baroni, Marco},
  journal       = {ArXiv preprint},
  title         = {Rat big, cat eaten! Ideas for a useful deep-agent protolanguage},
  year          = {2020},
  month         = mar,
  abstract      = {Deep-agent communities developing their own language-like communication protocol are a hot (or at least warm) topic in AI. Such agents could be very useful in machine-machine and human-machine interaction scenarios long before they have evolved a protocol as complex as human language. Here, I propose a small set of priorities we should focus on, if we want to get as fast as possible to a stage where deep agents speak a useful protolanguage.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2003.11922},
  eprint        = {2003.11922},
  file          = {:papers/Baroni2020 - Rat Big, Cat Eaten! Ideas for a Useful Deep Agent Protolanguage.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read},
  url           = {https://arxiv.org/abs/2003.11922}
}

@inproceedings{Baroni2022,
  author    = {Baroni, Marco and Dessi, Roberto and Lazaridou, Angeliki},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},
  title     = {Emergent Language-Based Coordination In Deep Multi-Agent Systems},
  year      = {2022},
  address   = {Abu Dubai, UAE},
  month     = dec,
  pages     = {11--16},
  publisher = {Association for Computational Linguistics},
  abstract  = {Large pre-trained deep networks are the standard building blocks of modern AI applications. This raises fundamental questions about how to control their behaviour and how to make them efficiently interact with each other. Deep net emergent communication tackles these challenges by studying how to induce communication protocols between neural network agents, and how to include humans in the communication loop. Traditionally, this research had focussed on relatively small-scale experiments where two networks had to develop a discrete code from scratch for referential communication. However, with the rise of large pre-trained language models that can work well on many tasks, the emphasis is now shifting on how to let these models interact through a language-like channel to engage in more complex behaviors. By reviewing several representative papers, we will provide an introduction to deep net emergent communication, we will cover various central topics from the present and recent past, as well as discussing current shortcomings and suggest future directions. The presentation is complemented by a hands-on section where participants will implement and analyze two emergent communications setups from the literature. The tutorial should be of interest to researchers wanting to develop more flexible AI systems, but also to cognitive scientists and linguists interested in the evolution of communication systems.},
  file      = {:papers/Baroni2022 - Emergent Language Based Coordination in Deep Multi Agent Systems.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://aclanthology.org/2022.emnlp-tutorials.3}
}

@article{Bartlett2005,
  author   = {Mark Bartlett and Dimitar Kazakov},
  journal  = {Connection Science},
  title    = {The origins of syntax: from navigation to language},
  year     = {2005},
  number   = {3-4},
  pages    = {271-288},
  volume   = {17},
  abstract = {This article suggests that the parser underlying
              human syntax may have originally evolved to assist
              navigation, a claim supported by computational
              simulations as well as evidence from neuroscience and
              psychology. We discuss two independent conjectures
              about the way in which navigation could have
              supported the emergence of this aspect of the human
              language faculty: firstly, by promoting the
              development of a parser; and secondly, by possibly
              providing a topic of discussion to which this parser
              could have been applied with minimum effort. The
              paper summarizes our previously published experiments
              and provides original results in support of the
              evolutionary advantages this type of communication
              can provide, compared with other foraging strategies.
              Another aspect studied in the experiments is the
              combination and range of environmental factors that
              make communication beneficial, focusing on the
              availability and volatility of resources. We suggest
              that the parser evolved for navigation might
              initially have been limited to handling regular
              languages, and describe a mechanism that may have
              created selective pressure for a context-free
              parser.},
  doi      = {10.1080/09540090500282479},
  file     = {:papers/Bartlett2005 - The Origins of Syntax_ from Navigation to Language.pdf:PDF},
  groups   = {Emergent Languages},
  url      = {http://dx.doi.org/10.1080/09540090500282479}
}

@inproceedings{Bay2006,
  author    = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  booktitle = {Computer Vision -- ECCV 2006},
  title     = {SURF: Speeded Up Robust Features},
  year      = {2006},
  address   = {Berlin, Heidelberg},
  editor    = {Leonardis, Ale{\v{s}} and Bischof, Horst and Pinz, Axel},
  pages     = {404--417},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.},
  file      = {:papers/Bay2006 - SURF_ Speeded up Robust Features.pdf:PDF},
  isbn      = {978-3-540-33833-8}
}

@article{Beattie2016,
  author        = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and KÃ¼ttler, Heinrich and Lefrancq, Andrew and Green, Simon and ValdÃ©s, VÃ­ctor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
  title         = {DeepMind Lab},
  year          = {2016},
  month         = dec,
  abstract      = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.03801},
  eprint        = {1612.03801},
  file          = {:papers/Beattie2016 - DeepMind Lab.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@inproceedings{Bender2020,
  author    = {Bender, Emily M. and Koller, Alexander},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data},
  year      = {2020},
  address   = {Online},
  month     = jul,
  pages     = {5185--5198},
  publisher = {Association for Computational Linguistics},
  abstract  = {The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {``}understanding{''} language or capturing {``}meaning{''}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {``}Taking Stock of Where We{'}ve Been and Where We{'}re Going{''}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.},
  doi       = {10.18653/v1/2020.acl-main.463},
  file      = {:papers/Bender2020 - Climbing Towards NLU_ on Meaning, Form, and Understanding in the Age of Data.pdf:PDF},
  url       = {https://aclanthology.org/2020.acl-main.463}
}

@inproceedings{Bender2021,
  author    = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  title     = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ð¦},
  year      = {2021},
  address   = {New York, NY, USA},
  pages     = {610â623},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '21},
  abstract  = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  doi       = {10.1145/3442188.3445922},
  file      = {:papers/Bender2021 - On the Dangers of Stochastic Parrots_ Can Language Models Be Too Big_.pdf:PDF},
  isbn      = {9781450383097},
  location  = {Virtual Event, Canada},
  numpages  = {14},
  url       = {https://doi.org/10.1145/3442188.3445922}
}

@inproceedings{Bisk2020,
  author    = {Bisk, Yonatan and Holtzman, Ari and Thomason, Jesse and Andreas, Jacob and Bengio, Yoshua and Chai, Joyce and Lapata, Mirella and Lazaridou, Angeliki and May, Jonathan and Nisnevich, Aleksandr and Pinto, Nicolas and Turian, Joseph},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  title     = {Experience Grounds Language},
  year      = {2020},
  address   = {Online},
  month     = nov,
  pages     = {8718--8735},
  publisher = {Association for Computational Linguistics},
  abstract  = {Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.},
  doi       = {10.18653/v1/2020.emnlp-main.703},
  file      = {:papers/Bisk2020 - Experience Grounds Language.pdf:PDF},
  url       = {https://aclanthology.org/2020.emnlp-main.703}
}

@article{Bouchacourt2018,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {How agents see things: On visual representations in an emergent language game},
  year          = {2018},
  month         = aug,
  abstract      = {There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents' symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017) and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we are interested in developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1808.10696},
  eprint        = {1808.10696},
  file          = {:papers/Bouchacourt2018 - How Agents See Things_ on Visual Representations in an Emergent Language Game.pdf:PDF},
  groups        = {MLT Thesis, Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@article{Bouchacourt2019,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {Miss Tools and Mr Fruit: Emergent communication in agents learning about object affordances},
  year          = {2019},
  month         = may,
  abstract      = {Recent research studies communication emergence in communities of deep network agents assigned a joint task, hoping to gain insights on human language evolution. We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants. By conducting a thorough pragmatic and semantic analysis of the emergent protocol, we show that the agents solve the shared task through genuine bilateral, referential communication. However, the agents develop multiple idiolects, which makes us conclude that full symmetry is not a sufficient condition for a common language to emerge.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.11871},
  eprint        = {1905.11871},
  file          = {:papers/Bouchacourt2019 - Miss Tools and Mr Fruit_ Emergent Communication in Agents Learning about Object Affordances.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Brown2020,
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal       = {Advances in neural information processing systems},
  title         = {Language Models are Few-Shot Learners},
  year          = {2020},
  pages         = {1877-1901},
  volume        = {33},
  archiveprefix = {arXiv},
  eprint        = {2005.14165},
  file          = {:papers/Brown2020 - Language Models Are Few Shot Learners.pdf:PDF},
  primaryclass  = {cs.CL}
}

@mastersthesis{CanoSantin2019,
  author = {Cano SantÃ­n, JosÃ© Miguel},
  school = {University of Gothenburg},
  title  = {Fast visual grounding in interaction},
  year   = {2019},
  month  = oct,
  type   = {mathesis},
  file   = {:papers/CanoSantin2019 - Fast Visual Grounding in Interaction.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{CanoSantin2020,
  author    = {Cano Sant{\'\i}n, Jos{\'e} Miguel and Dobnik, Simon and Ghanimifard, Mehdi},
  booktitle = {Proceedings of the Probability and Meaning Conference (PaM 2020)},
  title     = {Fast visual grounding in interaction: bringing few-shot learning with neural networks to an interactive robot},
  year      = {2020},
  address   = {Gothenburg},
  month     = jun,
  pages     = {53--61},
  publisher = {Association for Computational Linguistics},
  abstract  = {The major shortcomings of using neural networks with situated agents are that in incremental interaction very few learning examples are available and that their visual sensory representations are quite different from image caption datasets. In this work we adapt and evaluate a few-shot learning approach, Matching Networks (Vinyals et al., 2016), to conversational strategies of a robot interacting with a human tutor in order to efficiently learn to categorise objects that are presented to it and also investigate to what degree transfer learning from pre-trained models on images from different contexts can improve its performance. We discuss the implications of such learning on the nature of semantic representations the system has learned.},
  file      = {:papers/CanoSantin2020 - Fast Visual Grounding in Interaction_ Bringing Few Shot Learning with Neural Networks to an Interactive Robot.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2020.pam-1.7}
}

@inproceedings{Cao2018,
  author     = {Kris Cao and Angeliki Lazaridou and Marc Lanctot and Joel Z Leibo and Karl Tuyls and Stephen Clark},
  booktitle  = {International Conference on Learning Representations},
  title      = {Emergent Communication through Negotiation},
  year       = {2018},
  file       = {:papers/Cao2018 - Emergent Communication through Negotiation.pdf:PDF},
  groups     = {Emergent Languages},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://openreview.net/forum?id=Hk6WhagRW}
}

@article{Chaabouni2021,
  author     = {Rahma Chaabouni and Eugene Kharitonov and Emmanuel Dupoux and Marco Baroni},
  journal    = {Proceedings of the National Academy of Sciences},
  title      = {Communicating artificial neural networks develop efficient color-naming systems},
  year       = {2021},
  month      = {mar},
  number     = {12},
  volume     = {118},
  doi        = {10.1073/pnas.2016569118},
  file       = {:papers/Chaabouni2021 - Communicating Artificial Neural Networks Develop Efficient Color Naming Systems.pdf:PDF},
  groups     = {Emergent Languages},
  priority   = {prio2},
  publisher  = {Proceedings of the National Academy of Sciences},
  readstatus = {read}
}

@article{Chaabouni2020,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Bouchacourt, Diane and Dupoux, Emmanuel and Baroni, Marco},
  title         = {Compositionality and Generalization in Emergent Languages},
  year          = {2020},
  month         = apr,
  abstract      = {Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as \emph{compositionality}. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2004.09124},
  eprint        = {2004.09124},
  file          = {:papers/Chaabouni2020 - Compositionality and Generalization in Emergent Languages.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Chaabouni2019,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Dupoux, Emmanuel and Baroni, Marco},
  journal       = {Advances in Neural Information Processing Systems},
  title         = {Anti-efficient encoding in emergent communication},
  year          = {2019},
  month         = may,
  volume        = {32},
  abstract      = {Despite renewed interest in emergent language simulations with neural networks, little is known about the basic properties of the induced code, and how they compare to human language. One fundamental characteristic of the latter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words are efficiently associated to shorter strings. We study whether the same pattern emerges when two neural networks, a "speaker" and a "listener", are trained to play a signaling game. Surprisingly, we find that networks develop an \emph{anti-efficient} encoding scheme, in which the most frequent inputs are associated to the longest messages, and messages in general are skewed towards the maximum length threshold. This anti-efficient code appears easier to discriminate for the listener, and, unlike in human communication, the speaker does not impose a contrasting least-effort pressure towards brevity. Indeed, when the cost function includes a penalty for longer messages, the resulting message distribution starts respecting ZLA. Our analysis stresses the importance of studying the basic features of emergent communication in a highly controlled setup, to ensure the latter will not strand too far from human language. Moreover, we present a concrete illustration of how different functional pressures can lead to successful communication codes that lack basic properties of human language, thus highlighting the role such pressures play in the latter.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.12561},
  eprint        = {1905.12561},
  file          = {:papers/Chaabouni2019 - Anti Efficient Encoding in Emergent Communication.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@inproceedings{Chaabouni2022,
  author    = {Rahma Chaabouni and Florian Strub and Florent Altch{\'e} and Eugene Tarassov and Corentin Tallec and Elnaz Davoodi and Kory Wallace Mathewson and Olivier Tieleman and Angeliki Lazaridou and Bilal Piot},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication at Scale},
  year      = {2022},
  file      = {:papers/Chaabouni2022 - Emergent Communication at Scale.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=AUGBfDIV9rL}
}

@book{Clark1996,
  author    = {Clark, Herbert H.},
  publisher = {Cambridge University Press},
  title     = {Using language},
  year      = {1996},
  address   = {Cambridge},
  file      = {:papers/Clark1996 - Using Language.pdf:PDF},
  groups    = {Emergent Languages}
}

@article{Clark1986,
  author   = {Herbert H. Clark and Deanna Wilkes-Gibbs},
  journal  = {Cognition},
  title    = {Referring as a collaborative process},
  year     = {1986},
  issn     = {0010-0277},
  number   = {1},
  pages    = {1-39},
  volume   = {22},
  abstract = {In conversation, speakers and addressees work together in the making of a definite reference. In the model we propose, the speaker initiates the process by presenting or inviting a noun phrase. Before going on to the next contribution, the participants, if necessary, repair, expand on, or replace the noun phrase in an iterative process until they reach a version they mutually accept. In doing so they try to minimize their joint effort. The preferred procedure is for the speaker to present a simple noun phrase and for the addressee to accept it by allowing the next contribution to begin. We describe a communication task in which pairs of people conversed about arranging complex figures and show how the proposed model accounts for many features of the references they produced. The model follows, we suggest, from the mutual responsibility that participants in conversation bear toward the understanding of each utterance.
              RÃ©sumÃ©
              Au cours d' une conversation, les interlocuteurs travaillent ensemble pour construire une rÃ©fÃ©rence dÃ©finie. Dans le modÃ¨le proposÃ¨, le locuteur initie le processus en prÃ©sentant un syntagme nominal. Avant de passer Ã  la contribution suivante, les participants, si cela est nÃ©cessaire, corrigent, dÃ©veloppent ou remplacent ce syntagme nominal au cours d'un processus itÃ©ratif jusqu'a ce que soit atteinte une version que tout deux acceptent. En faisant cela ils essaient de minimiser l'effort conjoint. La procedure prÃ©fÃ©rÃ©e consiste pour le locuteur Ã  prÃ©senter un syntagme nominal simple et pour l'allocuteur d'accepter ce syntagme en donnant le feu vert pour l'Ã©change suivant. Nous dÃ©crivons une tache de communication an cours de laquelle deux personnes discutent l'agencement de figures complexes et nous montrons comment le modele proposÃ© rend compte de nombreux traits des rÃ©fÃ©rences produites. Le modÃ©le dÃ©coule, selon notre suggestion, de la responsabilitÃ© mutuelle que les participants prennent pour que soit compris chaque Ã©noncÃ© durant la conversation.},
  doi      = {https://doi.org/10.1016/0010-0277(86)90010-7},
  file     = {:papers/Clark1986 - Referring As a Collaborative Process.pdf:PDF},
  url      = {https://www.sciencedirect.com/science/article/pii/0010027786900107}
}

@book{Cooper2023,
  author    = {Cooper, Robin},
  publisher = {Oxford University Press Press},
  title     = {From Perception to Communication: A Theory of Types for Action and Meaning},
  year      = {2023},
  month     = {June 13},
  series    = {Oxford Studies in Semantics and Pragmatics},
  volume    = {16},
  annote    = {This is an open access title available under the terms of a CC BY-NC-ND 4.0 International licence. It is free to read at Oxford Scholarship Online and offered as a free PDF download from OUP and selected open access locations. This book characterizes a notion of type that covers both linguistic and non-linguistic action, and lays the foundations for a theory of action based on a Theory of Types with Records (TTR). Robin Cooper argues that a theory of language based on action allows the adoption of a perspective on linguistic content that is centred on interaction in dialogue; this approach is crucially different to the traditional view of natural languages as essentially similar to formal languages such as logics developed by philosophers or mathematicians. At the same time, he claims that the substantial technical advantages made by the formal language view of semantics can be incorporated into the action-based view, and that this can lead to important improvements in both intuitive understanding and empirical coverage. This enterprise uses types rather than possible worlds as commonly employed in studies of the semantics of natural language. Types are more tractable than possible worlds and offer greater potential for understanding the implementation of semantics both on machines and in biological brains.},
  file      = {:papers/Cooper2023 - From Perception to Communication_ a Theory of Types for Action and Meaning.pdf:PDF},
  groups    = {Emergent Languages}
}

@article{Dale1995,
  author    = {Dale, Robert and Reiter, Ehud},
  journal   = {Cognitive science},
  title     = {Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions},
  year      = {1995},
  number    = {2},
  pages     = {233--263},
  volume    = {19},
  doi       = {10.48550/ARXIV.CMP-LG/9504020},
  file      = {:papers/Dale1995 - Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions.pdf:PDF},
  groups    = {AI: Cognitive System, Emergent Languages},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {Elsevier}
}

@article{Dasgupta2023,
  author  = {Ishita Dasgupta and Christine Kaeser-Chen and Kenneth Marino and Arun Ahuja and Sheila Babayan and Felix Hill and Rob Fergus},
  journal = {ArXiv},
  title   = {Collaborating with language models for embodied reasoning},
  year    = {2023},
  volume  = {abs/2302.00763},
  file    = {:papers/Dasgupta2023 - Collaborating with Language Models for Embodied Reasoning.pdf:PDF},
  url     = {https://api.semanticscholar.org/CorpusID:253180684}
}

@mastersthesis{Graaf2020,
  author     = {de Graaf, Erik},
  school     = {University of Gothenburg},
  title      = {Kille: Learning Objects and Spatial Relations with Kinect},
  year       = {2020},
  month      = aug,
  type       = {mathesis},
  file       = {:papers/Graaf2020 - Kille_ Learning Objects and Spatial Relations with Kinect.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Deng2009,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {ImageNet: A large-scale hierarchical image database},
  year      = {2009},
  pages     = {248-255},
  doi       = {10.1109/CVPR.2009.5206848},
  file      = {:papers/Deng2009 - ImageNet_ a Large Scale Hierarchical Image Database.pdf:PDF}
}

@article{Dessi2021,
  author        = {DessÃ¬, Roberto and Kharitonov, Eugene and Baroni, Marco},
  title         = {Interpretable agent communication from scratch (with a generic visual processor emerging on the side)},
  year          = {2021},
  month         = jun,
  abstract      = {As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2106.04258},
  eprint        = {2106.04258},
  file          = {:papers/Dessi2021 - Interpretable Agent Communication from Scratch (with a Generic Visual Processor Emerging on the Side).pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{DeVault2015,
  author     = {David DeVault and Johnathan Mell and J. Gratch},
  booktitle  = {AAAI Spring Symposia},
  title      = {Toward Natural Turn-Taking in a Virtual Human Negotiation Agent},
  year       = {2015},
  file       = {:papers/DeVault2015 - Toward Natural Turn Taking in a Virtual Human Negotiation Agent.pdf:PDF},
  groups     = {Emergent Languages},
  readstatus = {skimmed}
}

@inproceedings{Devlin2019,
  author     = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle  = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  title      = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  year       = {2019},
  address    = {Minneapolis, Minnesota},
  month      = jun,
  pages      = {4171--4186},
  publisher  = {Association for Computational Linguistics},
  abstract   = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  doi        = {10.18653/v1/N19-1423},
  file       = {:papers/Devlin2019 - BERT_ Pre Training of Deep Bidirectional Transformers for Language Understanding.pdf:PDF},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://aclanthology.org/N19-1423}
}

@inproceedings{Dobnik2017,
  author     = {Simon Dobnik and Amelie Ãstbom},
  booktitle  = {Proceedings of Saardial: The 21st Workshop on the Semantics and Pragmatics of Dialogue},
  title      = {(Perceptual) grounding as interaction},
  year       = {2017},
  address    = {SaarbrÃ¼cken},
  editor     = {Volha Petukhova and Ye Tian},
  month      = aug,
  pages      = {17-26},
  publisher  = {SemDial},
  file       = {:papers/Dobnik2017 - (Perceptual) Grounding As Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read}
}

@inproceedings{Dobnik2017a,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {LinkÃ¶ping Electronic Conference Proceedings},
  title      = {KILLE: a Framework for Situated Agents for Learning Language Through Interaction},
  year       = {2017},
  address    = {LinkÃ¶pings universitet},
  publisher  = {LinkÃ¶ping University Electronic Press},
  file       = {:papers/Dobnik2017b - KILLE_ a Framework for Situated Agents for Learning Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read}
}

@inproceedings{Dobnik2017b,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {CEUR Workshop Proceedings},
  title      = {KILLE: learning grounded language through interaction},
  year       = {2017},
  address    = {Toulouse},
  month      = jul,
  publisher  = {CEUR},
  file       = {:papers/Dobnik2017c - KILLE_ Learning Grounded Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Dobnik2021,
  author    = {Dobnik, Simon and Silfversparre, Vera},
  booktitle = {Proceedings of the 25th Workshop on the Semantics and Pragmatics of Dialogue - Full Papers},
  title     = {The red cup on the left: Reference, coreference and attention in visual dialogue},
  year      = {2021},
  address   = {Potsdam, Germany},
  month     = sep,
  publisher = {SEMDIAL},
  file      = {:papers/Dobnik2021 - The Red Cup on the Left_ Reference, Coreference and Attention in Visual Dialogue.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {http://semdial.org/anthology/Z21-Dobnik_semdial_0008.pdf}
}

@inproceedings{Dobnik2018,
  author    = {Simon Dobnik and Axel Storckenfeldt},
  booktitle = {Proceedings of AixDial - Semdial 2018: The 22st Workshop on the Semantics and Pragmatics of Dialogue},
  title     = {Categorisation of conversational games in free dialogue over spatial scenes},
  year      = {2018},
  address   = {Aix-en-Provence},
  editor    = {Laurent PrÃ©vot and Magalie Ochs and BenoÃ®t Favre},
  month     = nov,
  publisher = {Semdial},
  file      = {:papers/Dobnik2018a - Categorisation of Conversational Games in Free Dialogue Over Spatial Scenes.pdf:PDF},
  groups    = {MLT Thesis}
}

@mastersthesis{Emampoor2022,
  author = {Emampoor, Yasmeen},
  school = {University of Gothenburg},
  title  = {There is a Microwave in the Hallway},
  year   = {2022},
  month  = apr,
  type   = {mathesis},
  file   = {:papers/Emampoor2022 - There Is a Microwave in the Hallway.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{Evtimova2018,
  author    = {Katrina Evtimova and Andrew Drozdov and Douwe Kiela and Kyunghyun Cho},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication in a Multi-Modal, Multi-Step Referential Game},
  year      = {2018},
  file      = {:papers/Evtimova2018 - Emergent Communication in a Multi Modal, Multi Step Referential Game.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=rJGZq6g0-}
}

@inproceedings{Field2021,
  author    = {Field, Anjalie and Blodgett, Su Lin and Waseem, Zeerak and Tsvetkov, Yulia},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  title     = {A Survey of Race, Racism, and Anti-Racism in {NLP}},
  year      = {2021},
  address   = {Online},
  month     = aug,
  pages     = {1905--1925},
  publisher = {Association for Computational Linguistics},
  abstract  = {Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.},
  doi       = {10.18653/v1/2021.acl-long.149},
  file      = {:papers/Field2021 - A Survey of Race, Racism, and Anti Racism in NLP.pdf:PDF},
  url       = {https://aclanthology.org/2021.acl-long.149}
}

@misc{Foerster2016,
  author        = {Jakob N. Foerster and Yannis M. Assael and Nando de Freitas and Shimon Whiteson},
  title         = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1605.06676},
  file          = {:papers/Foerster2016 - Learning to Communicate with Deep Multi Agent Reinforcement Learning.pdf:PDF},
  groups        = {Emergent Languages},
  primaryclass  = {cs.AI}
}

@inproceedings{Ghanimifard2019,
  author    = {Mehdi Ghanimifard and Simon Dobnik},
  booktitle = {Proceedings of the 12th International Conference on Natural Language Generation},
  title     = {What goes into a word: generating image descriptions with top-down spatial knowledge},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/w19-8668},
  file      = {:papers/Ghanimifard2019 - What Goes into a Word_ Generating Image Descriptions with Top down Spatial Knowledge.pdf:PDF},
  groups    = {AI: Cognitive System, Project}
}

@inproceedings{Gupta2020,
  author        = {Gupta, Abhinav and Resnick, Cinjon and Foerster, Jakob and Dai, Andrew and Cho, Kyunghyun},
  booktitle     = {Proceedings of the 5th Workshop on Representation Learning for NLP},
  title         = {Compositionality and Capacity in Emergent Languages},
  year          = {2020},
  month         = jul,
  pages         = {34--38},
  publisher     = {Association for Computational Linguistics},
  abstract      = {Many recent works have discussed the propensity, or lack thereof, for emergent languages to exhibit properties of natural languages. A favorite in the literature is learning compositionality. We note that most of those works have focused on communicative bandwidth as being of primary importance. While important, it is not the only contributing factor. In this paper, we investigate the learning biases that affect the efficacy and compositionality of emergent languages. Our foremost contribution is to explore how capacity of a neural network impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and channel bandwidth that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.11424},
  eprint        = {1910.11424},
  file          = {:papers/Gupta2020 - Compositionality and Capacity in Emergent Languages.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), Machine Learning (stat.ML), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  readstatus    = {read}
}

@article{Harnad1999,
  author        = {Stevan Harnad},
  journal       = {Physica D 42: 335-346},
  title         = {The Symbol Grounding Problem},
  year          = {1999},
  month         = jun,
  abstract      = {How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations," which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations," which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations," grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z").},
  archiveprefix = {arXiv},
  doi           = {10.1016/0167-2789(90)90087-6},
  eprint        = {cs/9906002},
  file          = {:papers/Harnad1999 - The Symbol Grounding Problem.pdf:PDF},
  groups        = {AI: Cognitive System},
  keywords      = {cs.AI, I.2.0},
  primaryclass  = {cs.AI},
  readstatus    = {read}
}

@inproceedings{Harris1988,
  author    = {Christopher G. Harris and M. J. Stephens},
  booktitle = {Alvey Vision Conference},
  title     = {A Combined Corner and Edge Detector},
  year      = {1988},
  volume    = {15},
  file      = {:papers/Harris1988 - A Combined Corner and Edge Detector.pdf:PDF},
  url       = {https://api.semanticscholar.org/CorpusID:1694378}
}


@inproceedings{Havrylov2017,
  author    = {Serhii Havrylov and Ivan Titov},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}},
  title     = {Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols},
  year      = {2017},
  editor    = {Isabelle Guyon and Ulrike von Luxburg and Samy Bengio and Hanna M. Wallach and Rob Fergus and S. V. N. Vishwanathan and Roman Garnett},
  pages     = {2149--2159},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/nips/HavrylovT17.bib},
  file      = {:papers/Havrylov2017 - Emergence of Language with Multi Agent Games_ Learning to Communicate with Sequences of Symbols.pdf:PDF},
  groups    = {Emergent Languages},
  timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/70222949cc0db89ab32c9969754d4758-Abstract.html}
}

@inproceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90},
  file      = {:papers/He2016 - Deep Residual Learning for Image Recognition.pdf:PDF}
}

@misc{Herdade2020,
  author        = {Simao Herdade and Armin Kappeler and Kofi Boakye and Joao Soares},
  title         = {Image Captioning: Transforming Objects into Words},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1906.05963},
  file          = {:papers/Herdade2020 - Image Captioning_ Transforming Objects into Words.pdf:PDF},
  primaryclass  = {cs.CV}
}

@article{Hill2020,
  author        = {Felix Hill and Olivier Tieleman and Tamara von Glehn and Nathaniel Wong and Hamza Merzic and Stephen Clark},
  title         = {Grounded Language Learning Fast and Slow},
  year          = {2020},
  month         = sep,
  abstract      = {Recent work has shown that large text-based neural language models, trained with conventional supervised learning objectives, acquire a surprising propensity for few- and one-shot learning. Here, we show that an embodied agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional reinforcement learning algorithms. After a single introduction to a novel object via continuous visual perception and a language prompt ("This is a dax"), the agent can re-identify the object and manipulate it as instructed ("Put the dax on the bed"). In doing so, it seamlessly integrates short-term, within-episode knowledge of the appropriate referent for the word "dax" with long-term lexical and motor knowledge acquired across episodes (i.e. "bed" and "putting"). We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful for later executing instructions. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for agents that interact with human users.},
  archiveprefix = {arXiv},
  eprint        = {2009.01719},
  file          = {:papers/Hill2020 - Grounded Language Learning Fast and Slow.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CL, cs.AI},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  readstatus    = {skimmed}
}

@article{Hill2019,
  author        = {Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L. and Santoro, Adam},
  title         = {Environmental drivers of systematicity and generalization in a situated agent},
  year          = {2019},
  month         = oct,
  abstract      = {The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.00571},
  eprint        = {1910.00571},
  file          = {:papers/Hill2019 - Environmental Drivers of Systematicity and Generalization in a Situated Agent.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@inproceedings{Ilinykh2022,
  author    = {Ilinykh, Nikolai and Emampoor, Yasmeen and Dobnik, Simon},
  booktitle = {Proceedings of the 15th International Conference on Natural Language Generation},
  title     = {Look and Answer the Question: On the Role of Vision in Embodied Question Answering},
  year      = {2022},
  address   = {Waterville, Maine, USA and virtual meeting},
  month     = jul,
  pages     = {236--245},
  publisher = {Association for Computational Linguistics},
  file      = {:papers/Ilinykh2022a - Look and Answer the Question_ on the Role of Vision in Embodied Question Answering.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2022.inlg-main.19}
}


@inproceedings{Jang2017,
  author    = {Eric Jang and Shixiang Gu and Ben Poole},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  title     = {Categorical Reparameterization with Gumbel-Softmax},
  year      = {2017},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/iclr/JangGP17.bib},
  file      = {:papers/Jang2016 - Categorical Reparameterization with Gumbel Softmax.pdf:PDF},
  timestamp = {Thu, 25 Jul 2019 14:26:04 +0200},
  url       = {https://openreview.net/forum?id=rkE3y85ee}
}

@inproceedings{Ji2022,
  author    = {Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert and Artzi, Yoav},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  title     = {Abstract Visual Reasoning with Tangram Shapes},
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  month     = dec,
  pages     = {582--601},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with {\textgreater}1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs.},
  file      = {:papers/Ji2022 - Abstract Visual Reasoning with Tangram Shapes.pdf:PDF},
  url       = {https://aclanthology.org/2022.emnlp-main.38}
}

@inproceedings{Johnson2017a,
  author        = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  booktitle     = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title         = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  year          = {2017},
  month         = dec,
  pages         = {2901--2910},
  publisher     = {arXiv},
  abstract      = {When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/JohnsonHMFZG16.bib},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.06890},
  eprint        = {1612.06890},
  file          = {:papers/Johnson2017a - CLEVR_ a Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning.pdf:PDF},
  groups        = {Emergent Languages},
  journal       = {CoRR},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  timestamp     = {Sat, 19 Oct 2019 16:30:04 +0200},
  url           = {http://arxiv.org/abs/1612.06890}
}

@inproceedings{Johnson2017,
  author    = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Hoffman, Judy and Fei-Fei, Li and Zitnick, C Lawrence and Girshick, Ross},
  booktitle = {Proceedings of the IEEE international conference on computer vision},
  title     = {Inferring and Executing Programs for Visual Reasoning},
  year      = {2017},
  pages     = {2989--2998},
  file      = {:papers/Johnson2017 - Inferring and Executing Programs for Visual Reasoning.pdf:PDF}
}

@inproceedings{Kelleher2020,
  author    = {John D. Kelleher and Dobnik, Simon},
  booktitle = {CLASP Papers in Computational Linguistics: Dialogue and Perception -- Extended papers from DaP-2018 Gothenburg},
  title     = {Referring to the recently seen: reference and perceptual memory in situated dialogue},
  year      = {2020},
  pages     = {41--50},
  abstract  = {From theoretical linguistic and cognitive perspectives, situated dialogue systems are interesting as they provide ideal test-beds for investigating the interaction between language and perception. To date, how- ever much of the work on situated dialogue has focused resolving anaphoric or exophoric references. This paper opens up the question of how perceptual memory and linguistic references interact, and the challenges that this poses to computational models of perceptually grounded dialogue.},
  crossref  = {DaP-2018-Extended},
  file      = {:papers/Kelleher2020 - Referring to the Recently Seen_ Reference and Perceptual Memory in Situated Dialogue.pdf:PDF},
  keywords  = {situated dialogue, reference resolution, perception, memory},
  url       = {https://gup.ub.gu.se/publication/294891?lang=en}
}

@inproceedings{Kelleher2017,
  author       = {Kelleher, John D. and Dobnik, Simon},
  booktitle    = {Proceedings of the Conference on Logic and Machine Learning in Natural Language (LaML 2017)},
  title        = {What is not where: the challenge of integrating spatial representations into deep learning architectures},
  year         = {2017},
  address      = {Gothenburg},
  editor       = {Dobnik, Simon; Lappin, Shalom},
  month        = jun,
  organization = {University of Gothenburg},
  publisher    = {Centre for Linguistic Theory and Studies in Probability (CLASP)},
  file         = {:papers/Kelleher2017 - What Is Not Where_ the Challenge of Integrating Spatial Representations into Deep Learning Architectures.pdf:PDF}
}

@inproceedings{Kharitonov2020,
  author    = {Kharitonov, Eugene and Baroni, Marco},
  booktitle = {Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  title     = {Emergent Language Generalization and Acquisition Speed are not tied to Compositionality},
  year      = {2020},
  address   = {Online},
  month     = nov,
  pages     = {11--15},
  publisher = {Association for Computational Linguistics},
  abstract  = {Studies of discrete languages emerging when neural agents communicate to solve a joint task often look for evidence of compositional structure. This stems for the expectation that such a structure would allow languages to be acquired faster by the agents and enable them to generalize better. We argue that these beneficial properties are only loosely connected to compositionality. In two experiments, we demonstrate that, depending on the task, non-compositional languages might show equal, or better, generalization performance and acquisition speed than compositional ones. Further research in the area should be clearer about what benefits are expected from compositionality, and how the latter would lead to them.},
  doi       = {10.18653/v1/2020.blackboxnlp-1.2},
  file      = {:papers/Kharitonov2020 - Emergent Language Generalization and Acquisition Speed Are Not Tied to Compositionality.pdf:PDF},
  url       = {https://aclanthology.org/2020.blackboxnlp-1.2}
}

@article{Kharitonov2019a,
  author        = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  title         = {Entropy Minimization In Emergent Languages},
  year          = {2019},
  month         = may,
  abstract      = {There is growing interest in studying the languages that emerge when neural agents are jointly trained to solve tasks requiring communication through a discrete channel. We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. That is, emergent languages are (nearly) as simple as the task they are developed for allow them to be. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.13687},
  eprint        = {1905.13687},
  file          = {:papers/Kharitonov2019a - Entropy Minimization in Emergent Languages.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Kharitonov2019,
  author    = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations},
  title     = {{EGG}: a toolkit for research on Emergence of lan{G}uage in Games},
  year      = {2019},
  address   = {Hong Kong, China},
  month     = nov,
  pages     = {55--60},
  publisher = {Association for Computational Linguistics},
  abstract  = {There is renewed interest in simulating language emergence among deep neural agents that communicate to jointly solve a task, spurred by the practical aim to develop language-enabled interactive AIs, as well as by theoretical questions about the evolution of human language. However, optimizing deep architectures connected by a discrete communication channel (such as that in which language emerges) is technically challenging. We introduce EGG, a toolkit that greatly simplifies the implementation of emergent-language communication games. EGG{'}s modular design provides a set of building blocks that the user can combine to create new games, easily navigating the optimization and architecture space. We hope that the tool will lower the technical barrier, and encourage researchers from various backgrounds to do original work in this exciting area.},
  doi       = {10.18653/v1/D19-3010},
  file      = {:papers/Kharitonov2019 - EGG_ a Toolkit for Research on Emergence of LanGuage in Games.pdf:PDF},
  url       = {https://aclanthology.org/D19-3010}
}

@article{Kirby2002,
  author  = {Kirby, Simon},
  journal = {Artificial Life},
  title   = {Natural Language From Artificial Life},
  year    = {2002},
  number  = {2},
  pages   = {185-215},
  volume  = {8},
  doi     = {10.1162/106454602320184248},
  file    = {:papers/Kirby2002 - Natural Language from Artificial Life.pdf:PDF},
  groups  = {Emergent Languages}
}

@article{Kirby2008,
  author   = {Simon Kirby and Hannah Cornish and Kenny Smith},
  journal  = {Proceedings of the National Academy of Sciences},
  title    = {Cumulative cultural evolution in the laboratory: An experimental approach to the origins of structure in human language},
  year     = {2008},
  number   = {31},
  pages    = {10681-10686},
  volume   = {105},
  abstract = {We introduce an experimental paradigm for studying the cumulative cultural evolution of language. In doing so we provide the first experimental validation for the idea that cultural transmission can lead to the appearance of design without a designer. Our experiments involve the iterated learning of artificial languages by human participants. We show that languages transmitted culturally evolve in such a way as to maximize their own transmissibility: over time, the languages in our experiments become easier to learn and increasingly structured. Furthermore, this structure emerges purely as a consequence of the transmission of language over generations, without any intentional design on the part of individual language learners. Previous computational and mathematical models suggest that iterated learning provides an explanation for the structure of human language and link particular aspects of linguistic structure with particular constraints acting on language during its transmission. The experimental work presented here shows that the predictions of these models, and models of cultural evolution more generally, can be tested in the laboratory.},
  doi      = {10.1073/pnas.0707835105},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.0707835105},
  file     = {:papers/Kirby2008 - Cumulative Cultural Evolution in the Laboratory_ an Experimental Approach to the Origins of Structure in Human Language.pdf:PDF},
  groups   = {Emergent Languages},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.0707835105}
}

@inproceedings{Klymenko2022,
  author    = {Klymenko, Oleksandra and Meisenbacher, Stephen and Matthes, Florian},
  booktitle = {Proceedings of the Fourth Workshop on Privacy in Natural Language Processing},
  title     = {Differential Privacy in Natural Language Processing The Story So Far},
  year      = {2022},
  address   = {Seattle, United States},
  month     = jul,
  pages     = {1--11},
  publisher = {Association for Computational Linguistics},
  abstract  = {As the tide of Big Data continues to influence the landscape of Natural Language Processing (NLP), the utilization of modern NLP methods has grounded itself in this data, in order to tackle a variety of text-based tasks. These methods without a doubt can include private or otherwise personally identifiable information. As such, the question of privacy in NLP has gained fervor in recent years, coinciding with the development of new Privacy- Enhancing Technologies (PETs). Among these PETs, Differential Privacy boasts several desirable qualities in the conversation surrounding data privacy. Naturally, the question becomes whether Differential Privacy is applicable in the largely unstructured realm of NLP. This topic has sparked novel research, which is unified in one basic goal how can one adapt Differential Privacy to NLP methods? This paper aims to summarize the vulnerabilities addressed by Differential Privacy, the current thinking, and above all, the crucial next steps that must be considered.},
  doi       = {10.18653/v1/2022.privatenlp-1.1},
  file      = {:papers/Klymenko2022 - Differential Privacy in Natural Language Processing the Story so Far.pdf:PDF},
  url       = {https://aclanthology.org/2022.privatenlp-1.1}
}

@article{Kottur2017,
  author        = {Kottur, Satwik and Moura, JosÃ© M. F. and Lee, Stefan and Batra, Dhruv},
  title         = {Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog},
  year          = {2017},
  month         = jun,
  abstract      = {A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision! In this paper, using a Task and Tell reference game between two agents as a testbed, we present a sequence of 'negative' results culminating in a 'positive' one -- showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge 'naturally', despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1706.08502},
  eprint        = {1706.08502},
  file          = {:papers/Kottur2017 - Natural Language Does Not Emerge 'Naturally' in Multi Agent Dialog.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio1},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Krahmer2012,
  author    = {Krahmer, Emiel and van Deemter, Kees},
  journal   = {Computational Linguistics},
  title     = {Computational Generation of Referring Expressions: A Survey},
  year      = {2012},
  month     = mar,
  number    = {1},
  pages     = {173--218},
  volume    = {38},
  address   = {Cambridge, MA},
  doi       = {10.1162/COLI_a_00088},
  file      = {:papers/Krahmer2012 - Computational Generation of Referring Expressions_ a Survey.pdf:PDF},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/J12-1006}
}

@article{Lazaridou2020,
  author        = {Lazaridou, Angeliki and Baroni, Marco},
  title         = {Emergent Multi-Agent Communication in the Deep Learning Era},
  year          = {2020},
  month         = jun,
  abstract      = {The ability to cooperate through language is a defining feature of humans. As the perceptual, motory and planning capabilities of deep artificial networks increase, researchers are studying whether they also can develop a shared language to interact. From a scientific perspective, understanding the conditions under which language evolves in communities of deep agents and its emergent features can shed light on human language evolution. From an applied perspective, endowing deep networks with the ability to solve problems interactively by communicating with each other and with us should make them more flexible and useful in everyday life. This article surveys representative recent language emergence studies from both of these two angles.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2006.02419},
  eprint        = {2006.02419},
  file          = {:papers/Lazaridou2020 - Emergent Multi Agent Communication in the Deep Learning Era.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio1},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Lazaridou2017,
  author        = {Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
  booktitle     = {International Conference on Learning Representations},
  title         = {Multi-Agent Cooperation and the Emergence of (Natural) Language},
  year          = {2017},
  month         = dec,
  abstract      = {The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.},
  archiveprefix = {arXiv},
  eprint        = {1612.07182},
  file          = {:papers/Lazaridou2017 - Multi Agent Cooperation and the Emergence of (Natural) Language.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis, Emergent Languages},
  keywords      = {cs.CL, cs.CV, cs.GT, cs.LG, cs.MA},
  primaryclass  = {cs.CL},
  readstatus    = {read}
}

@inproceedings{Lazaridou2018,
  author    = {Angeliki Lazaridou and Karl Moritz Hermann and Karl Tuyls and Stephen Clark},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input},
  year      = {2018},
  file      = {:papers/Lazaridou2018 - Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=HJGv1Z-AW}
}

@article{Lee2022,
  author        = {Jae Hee Lee and Matthias Kerzel and Kyra Ahrens and Cornelius Weber and Stefan Wermter},
  title         = {What is Right for Me is Not Yet Right for You: A Dataset for Grounding Relative Directions via Multi-Task Learning},
  year          = {2022},
  month         = may,
  abstract      = {Understanding spatial relations is essential for intelligent agents to act and communicate in the physical world. Relative directions are spatial relations that describe the relative positions of target objects with regard to the intrinsic orientation of reference objects. Grounding relative directions is more difficult than grounding absolute directions because it not only requires a model to detect objects in the image and to identify spatial relation based on this information, but it also needs to recognize the orientation of objects and integrate this information into the reasoning process. We investigate the challenging problem of grounding relative directions with end-to-end neural networks. To this end, we provide GRiD-3D, a novel dataset that features relative directions and complements existing visual question answering (VQA) datasets, such as CLEVR, that involve only absolute directions. We also provide baselines for the dataset with two established end-to-end VQA models. Experimental evaluations show that answering questions on relative directions is feasible when questions in the dataset simulate the necessary subtasks for grounding relative directions. We discover that those subtasks are learned in an order that reflects the steps of an intuitive pipeline for processing relative directions.},
  archiveprefix = {arXiv},
  eprint        = {2205.02671},
  file          = {:papers/Lee2022 - What Is Right for Me Is Not yet Right for You_ a Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups        = {Project, AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CV, cs.AI, cs.LG, I.2.6},
  primaryclass  = {cs.CV}
}

@book{Lewis1969,
  author    = {David Kellogg Lewis},
  publisher = {Cambridge, MA, USA: Wiley-Blackwell},
  title     = {Convention: A Philosophical Study},
  year      = {1969}
}

@inproceedings{Liu2022,
  author    = {Liu, Yinhong and Emerson, Guy},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Learning Functional Distributional Semantics with Visual Data},
  year      = {2022},
  address   = {Dublin, Ireland},
  month     = may,
  pages     = {3976--3988},
  publisher = {Association for Computational Linguistics},
  abstract  = {Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.},
  doi       = {10.18653/v1/2022.acl-long.275},
  file      = {:papers/Liu2022 - Learning Functional Distributional Semantics with Visual Data.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://aclanthology.org/2022.acl-long.275}
}

@misc{Liu2022a,
  author    = {Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  title     = {Visual Spatial Reasoning},
  year      = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.2205.00363},
  file      = {:papers/Liu2022a - Visual Spatial Reasoning.pdf:PDF},
  groups    = {Emergent Languages},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2205.00363}
}

@inproceedings{Lowe1999,
  author     = {D.G. Lowe},
  booktitle  = {Proceedings of the Seventh {IEEE} International Conference on Computer Vision},
  title      = {Object recognition from local scale-invariant features},
  year       = {1999},
  publisher  = {{IEEE}},
  doi        = {10.1109/iccv.1999.790410},
  file       = {:papers/Lowe1999 - Object Recognition from Local Scale Invariant Features.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Mitchell2013,
  author    = {Mitchell, Margaret and van Deemter, Kees and Reiter, Ehud},
  booktitle = {Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  title     = {Generating Expressions that Refer to Visible Objects},
  year      = {2013},
  address   = {Atlanta, Georgia},
  month     = jun,
  pages     = {1174--1184},
  publisher = {Association for Computational Linguistics},
  file      = {:papers/Mitchell2013 - Generating Expressions That Refer to Visible Objects.pdf:PDF},
  url       = {https://aclanthology.org/N13-1137}
}

@article{Monroe2017,
  author   = {Will Monroe and Robert Hawkins and Noah Goodman and Christopher Potts},
  journal  = {Transactions of the Association for Computational Linguistics},
  title    = {Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding},
  year     = {2017},
  issn     = {2307-387X},
  number   = {0},
  pages    = {325--338},
  volume   = {5},
  abstract = {We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.},
  file     = {:papers/Monroe2017 - Colors in Context_ a Pragmatic Neural Model for Grounded Language Understanding.pdf:PDF},
  groups   = {Emergent Languages},
  url      = {https://transacl.org/ojs/index.php/tacl/article/view/1142}
}

@misc{Monroe2018,
  author    = {Monroe, Will and Hu, Jennifer and Jong, Andrew and Potts, Christopher},
  title     = {Generating Bilingual Pragmatic Color References},
  year      = {2018},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.1803.03917},
  file      = {:papers/Monroe2018 - Generating Bilingual Pragmatic Color References.pdf:PDF},
  groups    = {Emergent Languages},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1803.03917}
}

@article{Noukhovitch2021,
  author        = {Noukhovitch, Michael and LaCroix, Travis and Lazaridou, Angeliki and Courville, Aaron},
  title         = {Emergent Communication under Competition},
  year          = {2021},
  month         = jan,
  abstract      = {The literature in modern machine learning has only negative results for learning to communicate between competitive agents using standard RL. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge in a competitive setting. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it can occur for partially competitive scenarios using standard learning algorithms. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game where previous work failed to learn communication between independent agents (Cao et al., 2018). We show that, in this setting, both agents must benefit from communication for it to emerge; and, with a slight modification to the game, we demonstrate successful communication between competitive agents. We hope this work overturns misconceptions and inspires more research in competitive emergent communication.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi           = {10.48550/ARXIV.2101.10276},
  eprint        = {2101.10276},
  file          = {:papers/Noukhovitch2021 - Emergent Communication under Competition.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.LG},
  publisher     = {arXiv}
}

@book{Regier1996,
  author    = {Regier, Terry},
  publisher = {MIT Press},
  title     = {The human semantic potential: spatial language and constrained connectionism},
  year      = {1996},
  address   = {Cambridge, Massachusetts, London, England},
  groups    = {Emergent Languages}
}

@article{Roy2005,
  author    = {Roy, Deb},
  journal   = {Artificial Intelligence},
  title     = {Semiotic schemas: a framework for grounding language in action and perception},
  year      = {2005},
  issn      = {0004-3702},
  month     = {September},
  number    = {1-2},
  pages     = {170--205},
  volume    = {167},
  address   = {Essex, UK},
  doi       = {10.1016/j.artint.2005.04.007},
  file      = {:papers/Roy2005 - Semiotic Schemas_ a Framework for Grounding Language in Action and Perception.pdf:PDF},
  groups    = {Emergent Languages},
  publisher = {Elsevier Science Publishers Ltd.},
  url       = {http://dx.doi.org/10.1016/j.artint.2005.04.007}
}

@article{Roy2002,
  author     = {Deb K. Roy},
  journal    = {Computer Speech, Language},
  title      = {Learning visually grounded words and syntax for a scene description task},
  year       = {2002},
  month      = {jul},
  number     = {3-4},
  pages      = {353--385},
  volume     = {16},
  doi        = {10.1016/s0885-2308(02)00024-4},
  file       = {:papers/Roy2002 - Learning Visually Grounded Words and Syntax for a Scene Description Task.pdf:PDF},
  groups     = {AI: Cognitive System},
  priority   = {prio1},
  publisher  = {Elsevier {BV}},
  readstatus = {read}
}

@inproceedings{Shah2020,
  author    = {Shah, Deven Santosh and Schwartz, H. Andrew and Hovy, Dirk},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview},
  year      = {2020},
  address   = {Online},
  month     = jul,
  pages     = {5248--5264},
  publisher = {Association for Computational Linguistics},
  abstract  = {An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.},
  doi       = {10.18653/v1/2020.acl-main.468},
  file      = {:papers/Shah2020 - Predictive Biases in Natural Language Processing Models_ a Conceptual Framework and Overview.pdf:PDF},
  url       = {https://aclanthology.org/2020.acl-main.468}
}


@inproceedings{Simonyan2015,
  author    = {Karen Simonyan and Andrew Zisserman},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year      = {2015},
  editor    = {Yoshua Bengio and Yann LeCun},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  file      = {:papers/Simonyan2015 - Very Deep Convolutional Networks for Large Scale Image Recognition.pdf:PDF},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  url       = {http://arxiv.org/abs/1409.1556}
}

@article{Steels2005,
  author    = {Steels, Luc and Belpaeme, Tony},
  journal   = {Behavioral and Brain Sciences},
  title     = {Coordinating perceptually grounded categories through language: A case study for colour},
  year      = {2005},
  number    = {4},
  pages     = {469â489},
  volume    = {28},
  doi       = {10.1017/S0140525X05000087},
  file      = {:papers/Steels2005 - Coordinating Perceptually Grounded Categories through Language_ a Case Study for Colour.pdf:PDF},
  groups    = {Emergent Languages},
  publisher = {Cambridge University Press}
}

@incollection{Steels2009,
  author    = {Luc Steels and Martin Loetzsch},
  booktitle = {Spatial Language and Dialogue},
  publisher = {Oxford University Press},
  title     = {Perspective Alignment in Spatial Language},
  year      = {2009},
  editor    = {Kenny R. Coventry and Thora Tenbrink and John A. Bateman},
  pages     = {70--88},
  series    = {Explorations in language and space},
  volume    = {3},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/books/ox/09/SteelsL09.bib},
  doi       = {10.1093/acprof:oso/9780199554201.003.0006},
  file      = {:papers/Steels2009 - Perspective Alignment in Spatial Language.pdf:PDF},
  timestamp = {Thu, 19 Nov 2020 09:11:25 +0100},
  url       = {https://doi.org/10.1093/acprof:oso/9780199554201.003.0006}
}

@mastersthesis{Storckenfeldt2018,
  author = {Storckenfeldt, Axel},
  school = {University of Gothenburg},
  title  = {Categorization of conversational games in free dialogue referring to spatial scenes},
  year   = {2018},
  month  = oct,
  type   = {candthesis},
  file   = {:papers/Storckenfeldt2018 - Categorization of Conversational Games in Free Dialogue Referring to Spatial Scenes.pdf:PDF},
  groups = {MLT Thesis}
}

@article{Tsimpoukelli2021,
  author        = {Tsimpoukelli, Maria and Menick, Jacob and Cabi, Serkan and Eslami, S. M. Ali and Vinyals, Oriol and Hill, Felix},
  title         = {Multimodal Few-Shot Learning with Frozen Language Models},
  year          = {2021},
  month         = jun,
  abstract      = {When trained at sufficient scale, auto-regressive language models exhibit the notable ability to learn a new language task after being prompted with just a few examples. Here, we present a simple, yet effective, approach for transferring this few-shot learning ability to a multimodal setting (vision and language). Using aligned image and caption data, we train a vision encoder to represent each image as a sequence of continuous embeddings, such that a pre-trained, frozen language model prompted with this prefix generates the appropriate caption. The resulting system is a multimodal few-shot learner, with the surprising ability to learn a variety of new tasks when conditioned on examples, represented as a sequence of multiple interleaved image and text embeddings. We demonstrate that it can rapidly learn words for new objects and novel visual categories, do visual question-answering with only a handful of examples, and make use of outside knowledge, by measuring a single model on a variety of established and new benchmarks.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2106.13884},
  eprint        = {2106.13884},
  file          = {:Tsimpoukelli2021 - Multimodal Few Shot Learning with Frozen Language Models.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv}
}

@inproceedings{Weidinger2022,
  author    = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
  booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  title     = {Taxonomy of Risks Posed by Language Models},
  year      = {2022},
  address   = {New York, NY, USA},
  pages     = {214â229},
  publisher = {Association for Computing Machinery},
  series    = {FAccT '22},
  abstract  = {Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from computer science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.},
  doi       = {10.1145/3531146.3533088},
  file      = {:papers/Weidinger2022 - Taxonomy of Risks Posed by Language Models.pdf:PDF},
  isbn      = {9781450393522},
  keywords  = {responsible AI, risk assessment, language models, responsible innovation, technology risks},
  location  = {Seoul, Republic of Korea},
  numpages  = {16},
  url       = {https://doi.org/10.1145/3531146.3533088}
}

@article{Williams1992,
  author     = {Ronald J. Williams},
  journal    = {Machine Learning},
  title      = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  year       = {1992},
  month      = {may},
  number     = {3-4},
  pages      = {229--256},
  volume     = {8},
  doi        = {10.1007/bf00992696},
  file       = {:papers/Williams1992 - Simple Statistical Gradient Following Algorithms for Connectionist Reinforcement Learning.pdf:PDF},
  groups     = {Emergent Languages},
  publisher  = {Springer Science and Business Media {LLC}},
  readstatus = {skimmed}
}

@book{Wittgenstein1953,
  author    = {Wittgenstein, Ludwig},
  publisher = {Basil Blackwell},
  title     = {Philosophische Untersuchungen},
  year      = {1953},
  address   = {Oxford},
  file      = {:papers/Wittgenstein1953 - Philosophische Untersuchungen.pdf:PDF},
  groups    = {Emergent Languages},
  language  = {German}
}

@inproceedings{Yosinski2014,
  author    = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle = {Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
  title     = {How Transferable Are Features in Deep Neural Networks?},
  year      = {2014},
  address   = {Cambridge, MA, USA},
  pages     = {3320â3328},
  publisher = {MIT Press},
  series    = {NIPS'14},
  abstract  = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  file      = {:papers/Yosinski2014 - How Transferable Are Features in Deep Neural Networks_.pdf:PDF},
  location  = {Montreal, Canada},
  numpages  = {9}
}

@article{Zaslavsky2018,
  author    = {Zaslavsky, Noga and Kemp, Charles and Regier, Terry and Tishby, Naftali},
  journal   = {Proceedings of the National Academy of Sciences},
  title     = {Efficient compression in color naming and its evolution},
  year      = {2018},
  number    = {31},
  pages     = {7937--7942},
  volume    = {115},
  file      = {:papers/Zaslavsky2018 - Efficient Compression in Color Naming and Its Evolution.pdf:PDF},
  groups    = {Emergent Languages},
  publisher = {National Acad Sciences},
  url       = {http://lclab.berkeley.edu/papers/zaslavsky-et-al-IB-
               2018.pdf}
}
