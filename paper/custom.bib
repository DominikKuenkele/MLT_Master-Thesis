@article{Ahrens2022,
  author        = {Kyra Ahrens and Matthias Kerzel and Jae Hee Lee and Cornelius Weber and Stefan Wermter},
  journal       = {IJCAI 2022 Workshop on Spatio-Temporal Reasoning and Learning},
  title         = {Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for Grounding Relative Directions via Multi-Task Learning},
  year          = {2022},
  month         = jul,
  abstract      = {Spatial reasoning poses a particular challenge for intelligent agents and is at the same time a prerequisite for their successful interaction and communication in the physical world. One such reasoning task is to describe the position of a target object with respect to the intrinsic orientation of some reference object via relative directions. In this paper, we introduce GRiD-A-3D, a novel diagnostic visual question-answering (VQA) dataset based on abstract objects. Our dataset allows for a fine-grained analysis of end-to-end VQA models' capabilities to ground relative directions. At the same time, model training requires considerably fewer computational resources compared with existing datasets, yet yields a comparable or even higher performance. Along with the new dataset, we provide a thorough evaluation based on two widely known end-to-end VQA architectures trained on GRiD-A-3D. We demonstrate that within a few epochs, the subtasks required to reason over relative directions, such as recognizing and locating objects in a scene and estimating their intrinsic orientations, are learned in the order in which relative directions are intuitively processed.},
  archiveprefix = {arXiv},
  eprint        = {2207.02624},
  file          = {:papers/Ahrens2022 - Knowing Earlier What Right Means to You_ a Comprehensive VQA Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups        = {Project, AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CV, cs.CL},
  primaryclass  = {cs.CV}
}

@mastersthesis{Aruqi2021,
  author = {Aruqi, Ali},
  school = {University of Gothenburg},
  title  = {EMBODIED QUESTION ANSWERING IN ROBOTIC ENVIRONMENT Automatic generation of a synthetic question-answer data-set},
  year   = {2021},
  month  = nov,
  type   = {mathesis},
  file   = {:papers/Aruqi2021 - EMBODIED QUESTION ANSWERING iN ROBOTIC ENVIRONMENT Automatic Generation of a Synthetic Question Answer Data Set.pdf:PDF},
  groups = {MLT Thesis}
}

@article{Baroni2020,
  author        = {Baroni, Marco},
  title         = {Rat big, cat eaten! Ideas for a useful deep-agent protolanguage},
  year          = {2020},
  month         = mar,
  abstract      = {Deep-agent communities developing their own language-like communication protocol are a hot (or at least warm) topic in AI. Such agents could be very useful in machine-machine and human-machine interaction scenarios long before they have evolved a protocol as complex as human language. Here, I propose a small set of priorities we should focus on, if we want to get as fast as possible to a stage where deep agents speak a useful protolanguage.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2003.11922},
  eprint        = {2003.11922},
  file          = {:papers/Baroni2020 - Rat Big, Cat Eaten! Ideas for a Useful Deep Agent Protolanguage.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{Baroni2022,
  author    = {Baroni, Marco and Dessi, Roberto and Lazaridou, Angeliki},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},
  title     = {Emergent Language-Based Coordination In Deep Multi-Agent Systems},
  year      = {2022},
  address   = {Abu Dubai, UAE},
  month     = dec,
  pages     = {11--16},
  publisher = {Association for Computational Linguistics},
  abstract  = {Large pre-trained deep networks are the standard building blocks of modern AI applications. This raises fundamental questions about how to control their behaviour and how to make them efficiently interact with each other. Deep net emergent communication tackles these challenges by studying how to induce communication protocols between neural network agents, and how to include humans in the communication loop. Traditionally, this research had focussed on relatively small-scale experiments where two networks had to develop a discrete code from scratch for referential communication. However, with the rise of large pre-trained language models that can work well on many tasks, the emphasis is now shifting on how to let these models interact through a language-like channel to engage in more complex behaviors. By reviewing several representative papers, we will provide an introduction to deep net emergent communication, we will cover various central topics from the present and recent past, as well as discussing current shortcomings and suggest future directions. The presentation is complemented by a hands-on section where participants will implement and analyze two emergent communications setups from the literature. The tutorial should be of interest to researchers wanting to develop more flexible AI systems, but also to cognitive scientists and linguists interested in the evolution of communication systems.},
  file      = {:papers/Baroni2022 - Emergent Language Based Coordination in Deep Multi Agent Systems.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://aclanthology.org/2022.emnlp-tutorials.3}
}

@article{Beattie2016,
  author        = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and Küttler, Heinrich and Lefrancq, Andrew and Green, Simon and Valdés, Víctor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
  title         = {DeepMind Lab},
  year          = {2016},
  month         = dec,
  abstract      = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.03801},
  eprint        = {1612.03801},
  file          = {:Beattie2016 - DeepMind Lab.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@article{Bouchacourt2018,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {How agents see things: On visual representations in an emergent language game},
  year          = {2018},
  month         = aug,
  abstract      = {There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents' symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017) and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we are interested in developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1808.10696},
  eprint        = {1808.10696},
  file          = {:Bouchacourt2018 - How Agents See Things_ on Visual Representations in an Emergent Language Game.pdf:PDF},
  groups        = {MLT Thesis, Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@article{Bouchacourt2019,
  author        = {Bouchacourt, Diane and Baroni, Marco},
  title         = {Miss Tools and Mr Fruit: Emergent communication in agents learning about object affordances},
  year          = {2019},
  month         = may,
  abstract      = {Recent research studies communication emergence in communities of deep network agents assigned a joint task, hoping to gain insights on human language evolution. We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants. By conducting a thorough pragmatic and semantic analysis of the emergent protocol, we show that the agents solve the shared task through genuine bilateral, referential communication. However, the agents develop multiple idiolects, which makes us conclude that full symmetry is not a sufficient condition for a common language to emerge.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.11871},
  eprint        = {1905.11871},
  file          = {:papers/Bouchacourt2019 - Miss Tools and Mr Fruit_ Emergent Communication in Agents Learning about Object Affordances.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@mastersthesis{CanoSantin2019,
  author = {Cano Santín, José Miguel},
  school = {University of Gothenburg},
  title  = {Fast visual grounding in interaction},
  year   = {2019},
  month  = oct,
  type   = {mathesis},
  file   = {:papers/CanoSantin2019 - Fast Visual Grounding in Interaction.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{CanoSantin2020,
  author    = {Cano Sant{\'\i}n, Jos{\'e} Miguel and Dobnik, Simon and Ghanimifard, Mehdi},
  booktitle = {Proceedings of the Probability and Meaning Conference (PaM 2020)},
  title     = {Fast visual grounding in interaction: bringing few-shot learning with neural networks to an interactive robot},
  year      = {2020},
  address   = {Gothenburg},
  month     = jun,
  pages     = {53--61},
  publisher = {Association for Computational Linguistics},
  abstract  = {The major shortcomings of using neural networks with situated agents are that in incremental interaction very few learning examples are available and that their visual sensory representations are quite different from image caption datasets. In this work we adapt and evaluate a few-shot learning approach, Matching Networks (Vinyals et al., 2016), to conversational strategies of a robot interacting with a human tutor in order to efficiently learn to categorise objects that are presented to it and also investigate to what degree transfer learning from pre-trained models on images from different contexts can improve its performance. We discuss the implications of such learning on the nature of semantic representations the system has learned.},
  file      = {:papers/CanoSantin2020 - Fast Visual Grounding in Interaction_ Bringing Few Shot Learning with Neural Networks to an Interactive Robot.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2020.pam-1.7}
}

@inproceedings{Cao2018,
  author     = {Kris Cao and Angeliki Lazaridou and Marc Lanctot and Joel Z Leibo and Karl Tuyls and Stephen Clark},
  booktitle  = {International Conference on Learning Representations},
  title      = {Emergent Communication through Negotiation},
  year       = {2018},
  file       = {:papers/Cao2018 - Emergent Communication through Negotiation.pdf:PDF},
  groups     = {Emergent Languages},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://openreview.net/forum?id=Hk6WhagRW}
}

@article{Chaabouni2021,
  author     = {Rahma Chaabouni and Eugene Kharitonov and Emmanuel Dupoux and Marco Baroni},
  journal    = {Proceedings of the National Academy of Sciences},
  title      = {Communicating artificial neural networks develop efficient color-naming systems},
  year       = {2021},
  month      = {mar},
  number     = {12},
  volume     = {118},
  doi        = {10.1073/pnas.2016569118},
  file       = {:papers/Chaabouni2021 - Communicating Artificial Neural Networks Develop Efficient Color Naming Systems.pdf:PDF},
  groups     = {Emergent Languages},
  priority   = {prio2},
  publisher  = {Proceedings of the National Academy of Sciences},
  readstatus = {read}
}

@article{Chaabouni2020,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Bouchacourt, Diane and Dupoux, Emmanuel and Baroni, Marco},
  title         = {Compositionality and Generalization in Emergent Languages},
  year          = {2020},
  month         = apr,
  abstract      = {Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as \emph{compositionality}. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2004.09124},
  eprint        = {2004.09124},
  file          = {:papers/Chaabouni2020 - Compositionality and Generalization in Emergent Languages.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Chaabouni2019,
  author        = {Chaabouni, Rahma and Kharitonov, Eugene and Dupoux, Emmanuel and Baroni, Marco},
  title         = {Anti-efficient encoding in emergent communication},
  year          = {2019},
  month         = may,
  abstract      = {Despite renewed interest in emergent language simulations with neural networks, little is known about the basic properties of the induced code, and how they compare to human language. One fundamental characteristic of the latter, known as Zipf's Law of Abbreviation (ZLA), is that more frequent words are efficiently associated to shorter strings. We study whether the same pattern emerges when two neural networks, a "speaker" and a "listener", are trained to play a signaling game. Surprisingly, we find that networks develop an \emph{anti-efficient} encoding scheme, in which the most frequent inputs are associated to the longest messages, and messages in general are skewed towards the maximum length threshold. This anti-efficient code appears easier to discriminate for the listener, and, unlike in human communication, the speaker does not impose a contrasting least-effort pressure towards brevity. Indeed, when the cost function includes a penalty for longer messages, the resulting message distribution starts respecting ZLA. Our analysis stresses the importance of studying the basic features of emergent communication in a highly controlled setup, to ensure the latter will not strand too far from human language. Moreover, we present a concrete illustration of how different functional pressures can lead to successful communication codes that lack basic properties of human language, thus highlighting the role such pressures play in the latter.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.12561},
  eprint        = {1905.12561},
  file          = {:papers/Chaabouni2019 - Anti Efficient Encoding in Emergent Communication.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv}
}

@inproceedings{Chaabouni2022,
  author    = {Rahma Chaabouni and Florian Strub and Florent Altch{\'e} and Eugene Tarassov and Corentin Tallec and Elnaz Davoodi and Kory Wallace Mathewson and Olivier Tieleman and Angeliki Lazaridou and Bilal Piot},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication at Scale},
  year      = {2022},
  file      = {:papers/Chaabouni2022 - Emergent Communication at Scale.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=AUGBfDIV9rL}
}

@mastersthesis{Graaf2020,
  author     = {de Graaf, Erik},
  school     = {University of Gothenburg},
  title      = {Kille: Learning Objects and Spatial Relations with Kinect},
  year       = {2020},
  month      = aug,
  type       = {mathesis},
  file       = {:papers/Graaf2020 - Kille_ Learning Objects and Spatial Relations with Kinect.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@article{Dale1995,
  author    = {Dale, Robert and Reiter, Ehud},
  title     = {Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions},
  year      = {1995},
  copyright = {Assumed arXiv.org perpetual, non-exclusive license to distribute this article for submissions made before January 2004},
  doi       = {10.48550/ARXIV.CMP-LG/9504020},
  file      = {:papers/Dale1995 - Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions.pdf:PDF},
  groups    = {AI: Cognitive System, Emergent Languages},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences},
  publisher = {arXiv}
}


@article{Dessi2021,
  author        = {Dessì, Roberto and Kharitonov, Eugene and Baroni, Marco},
  title         = {Interpretable agent communication from scratch (with a generic visual processor emerging on the side)},
  year          = {2021},
  month         = jun,
  abstract      = {As deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. Here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. We show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. The visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. Our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2106.04258},
  eprint        = {2106.04258},
  file          = {:papers/Dessi2021 - Interpretable Agent Communication from Scratch (with a Generic Visual Processor Emerging on the Side).pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@inproceedings{DeVault2015,
  author     = {David DeVault and Johnathan Mell and J. Gratch},
  booktitle  = {AAAI Spring Symposia},
  title      = {Toward Natural Turn-Taking in a Virtual Human Negotiation Agent},
  year       = {2015},
  file       = {:papers/DeVault2015 - Toward Natural Turn Taking in a Virtual Human Negotiation Agent.pdf:PDF},
  groups     = {Emergent Languages},
  readstatus = {skimmed}
}

@inproceedings{Dobnik2017,
  author     = {Simon Dobnik and Amelie Åstbom},
  booktitle  = {Proceedings of Saardial: The 21st Workshop on the Semantics and Pragmatics of Dialogue},
  title      = {(Perceptual) grounding as interaction},
  year       = {2017},
  address    = {Saarbrücken},
  editor     = {Volha Petukhova and Ye Tian},
  month      = aug,
  pages      = {17-26},
  publisher  = {SemDial},
  file       = {:papers/Dobnik2017a - (Perceptual) Grounding As Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read}
}

@inproceedings{Dobnik2017a,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {Linköping Electronic Conference Proceedings},
  title      = {KILLE: a Framework for Situated Agents for Learning Language Through Interaction},
  year       = {2017},
  address    = {Linköpings universitet},
  publisher  = {Linköping University Electronic Press},
  file       = {:papers/Dobnik2017b - KILLE_ a Framework for Situated Agents for Learning Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {read}
}

@inproceedings{Dobnik2017b,
  author     = {Simon Dobnik and Erik Wouter de Graaf},
  booktitle  = {CEUR Workshop Proceedings},
  title      = {KILLE: learning grounded language through interaction},
  year       = {2017},
  address    = {Toulouse},
  month      = jul,
  publisher  = {CEUR},
  file       = {:papers/Dobnik2017c - KILLE_ Learning Grounded Language through Interaction.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@inproceedings{Dobnik2021,
  author    = {Dobnik, Simon and Silfversparre, Vera},
  booktitle = {Proceedings of the 25th Workshop on the Semantics and Pragmatics of Dialogue - Full Papers},
  title     = {The red cup on the left: Reference, coreference and attention in visual dialogue},
  year      = {2021},
  address   = {Potsdam, Germany},
  month     = sep,
  publisher = {SEMDIAL},
  file      = {:papers/Dobnik2021 - The Red Cup on the Left_ Reference, Coreference and Attention in Visual Dialogue.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {http://semdial.org/anthology/Z21-Dobnik_semdial_0008.pdf}
}

@inproceedings{Dobnik2018,
  author    = {Simon Dobnik and Axel Storckenfeldt},
  booktitle = {Proceedings of AixDial - Semdial 2018: The 22st Workshop on the Semantics and Pragmatics of Dialogue},
  title     = {Categorisation of conversational games in free dialogue over spatial scenes},
  year      = {2018},
  address   = {Aix-en-Provence},
  editor    = {Laurent Prévot and Magalie Ochs and Benoît Favre},
  month     = nov,
  publisher = {Semdial},
  file      = {:papers/Dobnik2018a - Categorisation of Conversational Games in Free Dialogue Over Spatial Scenes.pdf:PDF},
  groups    = {MLT Thesis}
}

@mastersthesis{Emampoor2022,
  author = {Emampoor, Yasmeen},
  school = {University of Gothenburg},
  title  = {There is a Microwave in the Hallway},
  year   = {2022},
  month  = apr,
  type   = {mathesis},
  file   = {:papers/Emampoor2022 - There Is a Microwave in the Hallway.pdf:PDF},
  groups = {MLT Thesis}
}

@inproceedings{Evtimova2018,
  author    = {Katrina Evtimova and Andrew Drozdov and Douwe Kiela and Kyunghyun Cho},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergent Communication in a Multi-Modal, Multi-Step Referential Game},
  year      = {2018},
  file      = {:papers/Evtimova2018 - Emergent Communication in a Multi Modal, Multi Step Referential Game.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=rJGZq6g0-}
}

@inproceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep Residual Learning for Image Recognition},
  year      = {2016},
  pages     = {770-778},
  doi       = {10.1109/CVPR.2016.90},
  file      = {:papers/He2016 - Deep Residual Learning for Image Recognition.pdf:PDF}
}

@article{Hill2020,
  author        = {Felix Hill and Olivier Tieleman and Tamara von Glehn and Nathaniel Wong and Hamza Merzic and Stephen Clark},
  title         = {Grounded Language Learning Fast and Slow},
  year          = {2020},
  month         = sep,
  abstract      = {Recent work has shown that large text-based neural language models, trained with conventional supervised learning objectives, acquire a surprising propensity for few- and one-shot learning. Here, we show that an embodied agent situated in a simulated 3D world, and endowed with a novel dual-coding external memory, can exhibit similar one-shot word learning when trained with conventional reinforcement learning algorithms. After a single introduction to a novel object via continuous visual perception and a language prompt ("This is a dax"), the agent can re-identify the object and manipulate it as instructed ("Put the dax on the bed"). In doing so, it seamlessly integrates short-term, within-episode knowledge of the appropriate referent for the word "dax" with long-term lexical and motor knowledge acquired across episodes (i.e. "bed" and "putting"). We find that, under certain training conditions and with a particular memory writing mechanism, the agent's one-shot word-object binding generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. We further show how dual-coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful for later executing instructions. Together, the results demonstrate that deep neural networks can exploit meta-learning, episodic memory and an explicitly multi-modal environment to account for 'fast-mapping', a fundamental pillar of human cognitive development and a potentially transformative capacity for agents that interact with human users.},
  archiveprefix = {arXiv},
  eprint        = {2009.01719},
  file          = {:papers/Hill2020 - Grounded Language Learning Fast and Slow.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CL, cs.AI},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  readstatus    = {skimmed}
}

@article{Hill2019,
  author        = {Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L. and Santoro, Adam},
  title         = {Environmental drivers of systematicity and generalization in a situated agent},
  year          = {2019},
  month         = oct,
  abstract      = {The question of whether deep neural networks are good at generalising beyond their immediate training experience is of critical importance for learning-based approaches to AI. Here, we consider tests of out-of-sample generalisation that require an agent to respond to never-seen-before instructions by manipulating and positioning objects in a 3D Unity simulated room. We first describe a comparatively generic agent architecture that exhibits strong performance on these tests. We then identify three aspects of the training regime and environment that make a significant difference to its performance: (a) the number of object/word experiences in the training set; (b) the visual invariances afforded by the agent's perspective, or frame of reference; and (c) the variety of visual input inherent in the perceptual aspect of the agent's perception. Our findings indicate that the degree of generalisation that networks exhibit can depend critically on particulars of the environment in which a given task is instantiated. They further suggest that the propensity for neural networks to generalise in systematic ways may increase if, like human children, those networks have access to many frames of richly varying, multi-modal observations as they learn.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.00571},
  eprint        = {1910.00571},
  file          = {:papers/Hill2019 - Environmental Drivers of Systematicity and Generalization in a Situated Agent.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.AI},
  publisher     = {arXiv}
}

@inproceedings{Ilinykh2022,
  author    = {Ilinykh, Nikolai and Emampoor, Yasmeen and Dobnik, Simon},
  booktitle = {Proceedings of the 15th International Conference on Natural Language Generation},
  title     = {Look and Answer the Question: On the Role of Vision in Embodied Question Answering},
  year      = {2022},
  address   = {Waterville, Maine, USA and virtual meeting},
  month     = jul,
  pages     = {236--245},
  publisher = {Association for Computational Linguistics},
  file      = {:papers/Ilinykh2022a - Look and Answer the Question_ on the Role of Vision in Embodied Question Answering.pdf:PDF},
  groups    = {MLT Thesis},
  url       = {https://aclanthology.org/2022.inlg-main.19}
}

@article{Jang2016,
  author        = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  title         = {Categorical Reparameterization with Gumbel-Softmax},
  year          = {2016},
  month         = nov,
  abstract      = {Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1611.01144},
  eprint        = {1611.01144},
  file          = {:papers/Jang2016 - Categorical Reparameterization with Gumbel Softmax.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {stat.ML},
  publisher     = {arXiv},
  readstatus    = {skimmed}
}

@inproceedings{Ji2022,
  author    = {Ji, Anya and Kojima, Noriyuki and Rush, Noah and Suhr, Alane and Vong, Wai Keen and Hawkins, Robert and Artzi, Yoav},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  title     = {Abstract Visual Reasoning with Tangram Shapes},
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  month     = dec,
  pages     = {582--601},
  publisher = {Association for Computational Linguistics},
  abstract  = {We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with {\textgreater}1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs.},
  file      = {:papers/Ji2022 - Abstract Visual Reasoning with Tangram Shapes.pdf:PDF},
  url       = {https://aclanthology.org/2022.emnlp-main.38}
}

@article{Johnson2016,
  author        = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Zitnick, C. Lawrence and Girshick, Ross},
  journal       = {CoRR},
  title         = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  year          = {2016},
  month         = dec,
  volume        = {abs/1612.06890},
  abstract      = {When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/JohnsonHMFZG16.bib},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1612.06890},
  eprint        = {1612.06890},
  file          = {:papers/Johnson2016 - CLEVR_ a Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
  timestamp     = {Sat, 19 Oct 2019 16:30:04 +0200},
  url           = {http://arxiv.org/abs/1612.06890}
}

@article{Kharitonov2020,
  author        = {Kharitonov, Eugene and Baroni, Marco},
  title         = {Emergent Language Generalization and Acquisition Speed are not tied to Compositionality},
  year          = {2020},
  month         = apr,
  abstract      = {Studies of discrete languages emerging when neural agents communicate to solve a joint task often look for evidence of compositional structure. This stems for the expectation that such a structure would allow languages to be acquired faster by the agents and enable them to generalize better. We argue that these beneficial properties are only loosely connected to compositionality. In two experiments, we demonstrate that, depending on the task, non-compositional languages might show equal, or better, generalization performance and acquisition speed than compositional ones. Further research in the area should be clearer about what benefits are expected from compositionality, and how the latter would lead to them.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2004.03420},
  eprint        = {2004.03420},
  file          = {:papers/Kharitonov2020 - Emergent Language Generalization and Acquisition Speed Are Not Tied to Compositionality.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Kharitonov2019,
  author        = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  title         = {EGG: a toolkit for research on Emergence of lanGuage in Games},
  year          = {2019},
  month         = jul,
  abstract      = {There is renewed interest in simulating language emergence among deep neural agents that communicate to jointly solve a task, spurred by the practical aim to develop language-enabled interactive AIs, as well as by theoretical questions about the evolution of human language. However, optimizing deep architectures connected by a discrete communication channel (such as that in which language emerges) is technically challenging. We introduce EGG, a toolkit that greatly simplifies the implementation of emergent-language communication games. EGG's modular design provides a set of building blocks that the user can combine to create new games, easily navigating the optimization and architecture space. We hope that the tool will lower the technical barrier, and encourage researchers from various backgrounds to do original work in this exciting area.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1907.00852},
  eprint        = {1907.00852},
  file          = {:papers/Kharitonov2019 - EGG_ a Toolkit for Research on Emergence of LanGuage in Games.pdf:PDF},
  groups        = {MLT Thesis, Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Kharitonov2019a,
  author        = {Kharitonov, Eugene and Chaabouni, Rahma and Bouchacourt, Diane and Baroni, Marco},
  title         = {Entropy Minimization In Emergent Languages},
  year          = {2019},
  month         = may,
  abstract      = {There is growing interest in studying the languages that emerge when neural agents are jointly trained to solve tasks requiring communication through a discrete channel. We investigate here the information-theoretic complexity of such languages, focusing on the basic two-agent, one-exchange setup. We find that, under common training procedures, the emergent languages are subject to an entropy minimization pressure that has also been detected in human language, whereby the mutual information between the communicating agent's inputs and the messages is minimized, within the range afforded by the need for successful communication. That is, emergent languages are (nearly) as simple as the task they are developed for allow them to be. This pressure is amplified as we increase communication channel discreteness. Further, we observe that stronger discrete-channel-driven entropy minimization leads to representations with increased robustness to overfitting and adversarial attacks. We conclude by discussing the implications of our findings for the study of natural and artificial communication systems.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1905.13687},
  eprint        = {1905.13687},
  file          = {:papers/Kharitonov2019a - Entropy Minimization in Emergent Languages.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio2},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Kirby2008,
  author   = {Simon Kirby and Hannah Cornish and Kenny Smith},
  journal  = {Proceedings of the National Academy of Sciences},
  title    = {Cumulative cultural evolution in the laboratory: An experimental approach to the origins of structure in human language},
  year     = {2008},
  number   = {31},
  pages    = {10681-10686},
  volume   = {105},
  abstract = {We introduce an experimental paradigm for studying the cumulative cultural evolution of language. In doing so we provide the first experimental validation for the idea that cultural transmission can lead to the appearance of design without a designer. Our experiments involve the iterated learning of artificial languages by human participants. We show that languages transmitted culturally evolve in such a way as to maximize their own transmissibility: over time, the languages in our experiments become easier to learn and increasingly structured. Furthermore, this structure emerges purely as a consequence of the transmission of language over generations, without any intentional design on the part of individual language learners. Previous computational and mathematical models suggest that iterated learning provides an explanation for the structure of human language and link particular aspects of linguistic structure with particular constraints acting on language during its transmission. The experimental work presented here shows that the predictions of these models, and models of cultural evolution more generally, can be tested in the laboratory.},
  doi      = {10.1073/pnas.0707835105},
  eprint   = {https://www.pnas.org/doi/pdf/10.1073/pnas.0707835105},
  file     = {:papers/Kirby2008 - Cumulative Cultural Evolution in the Laboratory_ an Experimental Approach to the Origins of Structure in Human Language.pdf:PDF},
  groups   = {Emergent Languages},
  url      = {https://www.pnas.org/doi/abs/10.1073/pnas.0707835105}
}

@article{Kottur2017,
  author        = {Kottur, Satwik and Moura, José M. F. and Lee, Stefan and Batra, Dhruv},
  title         = {Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog},
  year          = {2017},
  month         = jun,
  abstract      = {A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, all learned without any human supervision! In this paper, using a Task and Tell reference game between two agents as a testbed, we present a sequence of 'negative' results culminating in a 'positive' one -- showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge 'naturally', despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1706.08502},
  eprint        = {1706.08502},
  file          = {:papers/Kottur2017 - Natural Language Does Not Emerge 'Naturally' in Multi Agent Dialog.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio1},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Lazaridou2020,
  author        = {Lazaridou, Angeliki and Baroni, Marco},
  title         = {Emergent Multi-Agent Communication in the Deep Learning Era},
  year          = {2020},
  month         = jun,
  abstract      = {The ability to cooperate through language is a defining feature of humans. As the perceptual, motory and planning capabilities of deep artificial networks increase, researchers are studying whether they also can develop a shared language to interact. From a scientific perspective, understanding the conditions under which language evolves in communities of deep agents and its emergent features can shed light on human language evolution. From an applied perspective, endowing deep networks with the ability to solve problems interactively by communicating with each other and with us should make them more flexible and useful in everyday life. This article surveys representative recent language emergence studies from both of these two angles.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2006.02419},
  eprint        = {2006.02419},
  file          = {:papers/Lazaridou2020 - Emergent Multi Agent Communication in the Deep Learning Era.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  priority      = {prio1},
  publisher     = {arXiv},
  readstatus    = {read}
}

@article{Lazaridou2016,
  author        = {Angeliki Lazaridou and Alexander Peysakhovich and Marco Baroni},
  title         = {Multi-Agent Cooperation and the Emergence of (Natural) Language},
  year          = {2016},
  month         = dec,
  abstract      = {The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the "word meanings" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.},
  archiveprefix = {arXiv},
  eprint        = {1612.07182},
  file          = {:papers/Lazaridou2016 - Multi Agent Cooperation and the Emergence of (Natural) Language.pdf:PDF},
  groups        = {AI: Cognitive System, MLT Thesis, Emergent Languages},
  keywords      = {cs.CL, cs.CV, cs.GT, cs.LG, cs.MA},
  primaryclass  = {cs.CL},
  readstatus    = {read}
}

@inproceedings{Lazaridou2018,
  author    = {Angeliki Lazaridou and Karl Moritz Hermann and Karl Tuyls and Stephen Clark},
  booktitle = {International Conference on Learning Representations},
  title     = {Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input},
  year      = {2018},
  file      = {:papers/Lazaridou2018 - Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input.pdf:PDF},
  groups    = {Emergent Languages},
  url       = {https://openreview.net/forum?id=HJGv1Z-AW}
}

@article{Lee2022,
  author        = {Jae Hee Lee and Matthias Kerzel and Kyra Ahrens and Cornelius Weber and Stefan Wermter},
  title         = {What is Right for Me is Not Yet Right for You: A Dataset for Grounding Relative Directions via Multi-Task Learning},
  year          = {2022},
  month         = may,
  abstract      = {Understanding spatial relations is essential for intelligent agents to act and communicate in the physical world. Relative directions are spatial relations that describe the relative positions of target objects with regard to the intrinsic orientation of reference objects. Grounding relative directions is more difficult than grounding absolute directions because it not only requires a model to detect objects in the image and to identify spatial relation based on this information, but it also needs to recognize the orientation of objects and integrate this information into the reasoning process. We investigate the challenging problem of grounding relative directions with end-to-end neural networks. To this end, we provide GRiD-3D, a novel dataset that features relative directions and complements existing visual question answering (VQA) datasets, such as CLEVR, that involve only absolute directions. We also provide baselines for the dataset with two established end-to-end VQA models. Experimental evaluations show that answering questions on relative directions is feasible when questions in the dataset simulate the necessary subtasks for grounding relative directions. We discover that those subtasks are learned in an order that reflects the steps of an intuitive pipeline for processing relative directions.},
  archiveprefix = {arXiv},
  eprint        = {2205.02671},
  file          = {:papers/Lee2022 - What Is Right for Me Is Not yet Right for You_ a Dataset for Grounding Relative Directions Via Multi Task Learning.pdf:PDF},
  groups        = {Project, AI: Cognitive System, MLT Thesis},
  keywords      = {cs.CV, cs.AI, cs.LG, I.2.6},
  primaryclass  = {cs.CV}
}

@inproceedings{Liu2022,
  author    = {Liu, Yinhong and Emerson, Guy},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {Learning Functional Distributional Semantics with Visual Data},
  year      = {2022},
  address   = {Dublin, Ireland},
  month     = may,
  pages     = {3976--3988},
  publisher = {Association for Computational Linguistics},
  abstract  = {Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.},
  doi       = {10.18653/v1/2022.acl-long.275},
  file      = {:papers/Liu2022 - Learning Functional Distributional Semantics with Visual Data.pdf:PDF},
  url       = {https://aclanthology.org/2022.acl-long.275}
}

@misc{Liu2022a,
  author    = {Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  title     = {Visual Spatial Reasoning},
  year      = {2022},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.2205.00363},
  file      = {:papers/Liu2022a - Visual Spatial Reasoning.pdf:PDF},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/2205.00363}
}

@inproceedings{Lowe1999,
  author     = {D.G. Lowe},
  booktitle  = {Proceedings of the Seventh {IEEE} International Conference on Computer Vision},
  title      = {Object recognition from local scale-invariant features},
  year       = {1999},
  publisher  = {{IEEE}},
  doi        = {10.1109/iccv.1999.790410},
  file       = {:papers/Lowe1999 - Object Recognition from Local Scale Invariant Features.pdf:PDF},
  groups     = {MLT Thesis},
  readstatus = {skimmed}
}

@article{Monroe2017,
  author   = {Will Monroe and Robert Hawkins and Noah Goodman and Christopher Potts},
  journal  = {Transactions of the Association for Computational Linguistics},
  title    = {Colors in Context: A Pragmatic Neural Model for Grounded Language Understanding},
  year     = {2017},
  issn     = {2307-387X},
  number   = {0},
  pages    = {325--338},
  volume   = {5},
  abstract = {We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built, and that much of this improvement results from combining the speaker and listener perspectives. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.},
  file     = {:papers/Monroe2017 - Colors in Context_ a Pragmatic Neural Model for Grounded Language Understanding.pdf:PDF},
  url      = {https://transacl.org/ojs/index.php/tacl/article/view/1142}
}

@misc{Monroe2018,
  author    = {Monroe, Will and Hu, Jennifer and Jong, Andrew and Potts, Christopher},
  title     = {Generating Bilingual Pragmatic Color References},
  year      = {2018},
  copyright = {Creative Commons Attribution 4.0 International},
  doi       = {10.48550/ARXIV.1803.03917},
  file      = {:papers/Monroe2018 - Generating Bilingual Pragmatic Color References.pdf:PDF},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  url       = {https://arxiv.org/abs/1803.03917}
}

@article{Noukhovitch2021,
  author        = {Noukhovitch, Michael and LaCroix, Travis and Lazaridou, Angeliki and Courville, Aaron},
  title         = {Emergent Communication under Competition},
  year          = {2021},
  month         = jan,
  abstract      = {The literature in modern machine learning has only negative results for learning to communicate between competitive agents using standard RL. We introduce a modified sender-receiver game to study the spectrum of partially-competitive scenarios and show communication can indeed emerge in a competitive setting. We empirically demonstrate three key takeaways for future research. First, we show that communication is proportional to cooperation, and it can occur for partially competitive scenarios using standard learning algorithms. Second, we highlight the difference between communication and manipulation and extend previous metrics of communication to the competitive case. Third, we investigate the negotiation game where previous work failed to learn communication between independent agents (Cao et al., 2018). We show that, in this setting, both agents must benefit from communication for it to emerge; and, with a slight modification to the game, we demonstrate successful communication between competitive agents. We hope this work overturns misconceptions and inspires more research in competitive emergent communication.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
  doi           = {10.48550/ARXIV.2101.10276},
  eprint        = {2101.10276},
  file          = {:papers/Noukhovitch2021 - Emergent Communication under Competition.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Multiagent Systems (cs.MA), FOS: Computer and information sciences},
  primaryclass  = {cs.LG},
  publisher     = {arXiv}
}

@article{Resnick2019,
  author        = {Resnick, Cinjon and Gupta, Abhinav and Foerster, Jakob and Dai, Andrew M. and Cho, Kyunghyun},
  title         = {Capacity, Bandwidth, and Compositionality in Emergent Language Learning},
  year          = {2019},
  month         = oct,
  abstract      = {Many recent works have discussed the propensity, or lack thereof, for emergent languages to exhibit properties of natural languages. A favorite in the literature is learning compositionality. We note that most of those works have focused on communicative bandwidth as being of primary importance. While important, it is not the only contributing factor. In this paper, we investigate the learning biases that affect the efficacy and compositionality of emergent languages. Our foremost contribution is to explore how capacity of a neural network impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and channel bandwidth that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1910.11424},
  eprint        = {1910.11424},
  file          = {:papers/Resnick2019 - Capacity, Bandwidth, and Compositionality in Emergent Language Learning.pdf:PDF},
  groups        = {Emergent Languages},
  keywords      = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Multiagent Systems (cs.MA), Machine Learning (stat.ML), FOS: Computer and information sciences},
  primaryclass  = {cs.CL},
  publisher     = {arXiv},
  readstatus    = {read}
}


@inproceedings{Simonyan2015,
  author    = {Karen Simonyan and Andrew Zisserman},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  year      = {2015},
  editor    = {Yoshua Bengio and Yann LeCun},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/corr/SimonyanZ14a.bib},
  file      = {:papers/Simonyan2015 - Very Deep Convolutional Networks for Large Scale Image Recognition.pdf:PDF},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  url       = {http://arxiv.org/abs/1409.1556}
}

@article{Steels2005,
  author    = {Steels, Luc and Belpaeme, Tony},
  journal   = {Behavioral and Brain Sciences},
  title     = {Coordinating perceptually grounded categories through language: A case study for colour},
  year      = {2005},
  number    = {4},
  pages     = {469–489},
  volume    = {28},
  doi       = {10.1017/S0140525X05000087},
  file      = {:papers/Steels2005 - Coordinating Perceptually Grounded Categories through Language_ a Case Study for Colour.pdf:PDF},
  publisher = {Cambridge University Press}
}

@mastersthesis{Storckenfeldt2018,
  author = {Storckenfeldt, Axel},
  school = {University of Gothenburg},
  title  = {Categorization of conversational games in free dialogue referring to spatial scenes},
  year   = {2018},
  month  = oct,
  type   = {candthesis},
  file   = {:papers/Storckenfeldt2018 - Categorization of Conversational Games in Free Dialogue Referring to Spatial Scenes.pdf:PDF},
  groups = {MLT Thesis}
}

@article{Tsimpoukelli2021,
  author        = {Tsimpoukelli, Maria and Menick, Jacob and Cabi, Serkan and Eslami, S. M. Ali and Vinyals, Oriol and Hill, Felix},
  title         = {Multimodal Few-Shot Learning with Frozen Language Models},
  year          = {2021},
  month         = jun,
  abstract      = {When trained at sufficient scale, auto-regressive language models exhibit the notable ability to learn a new language task after being prompted with just a few examples. Here, we present a simple, yet effective, approach for transferring this few-shot learning ability to a multimodal setting (vision and language). Using aligned image and caption data, we train a vision encoder to represent each image as a sequence of continuous embeddings, such that a pre-trained, frozen language model prompted with this prefix generates the appropriate caption. The resulting system is a multimodal few-shot learner, with the surprising ability to learn a variety of new tasks when conditioned on examples, represented as a sequence of multiple interleaved image and text embeddings. We demonstrate that it can rapidly learn words for new objects and novel visual categories, do visual question-answering with only a handful of examples, and make use of outside knowledge, by measuring a single model on a variety of established and new benchmarks.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2106.13884},
  eprint        = {2106.13884},
  file          = {:Tsimpoukelli2021 - Multimodal Few Shot Learning with Frozen Language Models.pdf:PDF},
  groups        = {MLT Thesis},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv}
}

@article{Williams1992,
  author     = {Ronald J. Williams},
  journal    = {Machine Learning},
  title      = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  year       = {1992},
  month      = {may},
  number     = {3-4},
  pages      = {229--256},
  volume     = {8},
  doi        = {10.1007/bf00992696},
  file       = {:papers/Williams1992 - Simple Statistical Gradient Following Algorithms for Connectionist Reinforcement Learning.pdf:PDF},
  groups     = {Emergent Languages},
  publisher  = {Springer Science and Business Media {LLC}},
  readstatus = {skimmed}
}
